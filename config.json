{
    "GEMMCublasLt": {
        "inputs": {
            "m": {
                "start": 16,
                "end": 4096,
                "interval": 16
            },
            "n": {
                "start": 16,
                "end": 4096,
                "interval": 16
            },
            "k": {
                "start": 16,
                "end": 4096,
                "interval": 16
            },
            "duration": 120,
            "datatype": "fp8e4m3"
        }
    },

    "NCCLBandwidth": {
        "inputs": {
            "start": "8",
            "end": "8G",
            "num_gpus": 8
        }
    },

    "HBMBandwidth": {
        "inputs": {
            "interval": 10,
            "num_runs": 10
        }
    },

    "NVBandwidth": {
        "inputs": {
            "num_runs": 1,
            "interval": 5
        }
    },

    "LLMBenchmark": {
        "credentials": {
            "hf_username" : "",
            "hf_password" : ""
        },

        "models": {
            "Mistral-7B-v0.1":{
                "use_model": false,
                "hf_url": "https://huggingface.co/mistralai/Mistral-7B-v0.1",
                "type": "llama",
                "batch_sizes": [32,64],
                "input_output_sizes": ["128,128"],
                "tp_sizes": [1],
                "warmup": 10,
                "number_of_runs": 5,
                "precision": "fp8"
            },

            "Meta-Llama-3-8B":{
                "use_model": false,
                "hf_url": "https://huggingface.co/meta-llama/Meta-Llama-3-8B",
                "type": "llama",
                "batch_sizes": [32,64],
                "input_output_sizes": ["128,128"],
                "tp_sizes": [1],
                "warmup": 10,
                "number_of_runs": 5,
                "precision": "fp8"
            },

            "Phi-3-medium-128k-instruct":{
                "use_model": false,
                "hf_url": "https://huggingface.co/microsoft/Phi-3-medium-128k-instruct",
                "type": "phi",
                "batch_sizes": [32,64],
                "input_output_sizes": ["128,128"],
                "tp_sizes": [1],
                "warmup": 10,
                "number_of_runs": 3,
                "precision": "float16"
            },

            "Meta-Llama-3-70B":{
                "use_model": false,
                "hf_url": "https://huggingface.co/meta-llama/Meta-Llama-3-70B",
                "type": "llama",
                "batch_sizes": [16,32,64],
                "input_output_sizes": ["128,128"],
                "tp_sizes": [8],
                "warmup": 10,
                "number_of_runs": 3,
                "precision": "fp8"
            },

            "Meta-Llama-3.1-405B-FP8":{
                "use_model": false,
                "hf_url": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-FP8",
                "type": "llama",
                "batch_sizes": [16,32,64,96],
                "input_output_sizes": ["128,128"],
                "tp_sizes": [8],
                "warmup": 10,
                "number_of_runs": 3,
                "precision": "bfloat16"
            },

            "Llama-2-70B-hf":{
                "use_model": false,
                "hf_url": "https://huggingface.co/meta-llama/Llama-2-70b-hf",
                "type": "llama",
                "batch_sizes": [16,32,64],
                "input_output_sizes": ["128,128"],
                "tp_sizes": [8],
                "warmup": 10,
                "number_of_runs": 3,
                "precision": "fp8"
            },

            "Llama-2-7B-hf":{
                "use_model": false,
                "hf_url": "https://huggingface.co/meta-llama/Llama-2-7b-hf",
                "type": "llama",
                "batch_sizes": [16,32,64],
                "input_output_sizes": ["128,128"],
                "tp_sizes": [1],
                "warmup": 10,
                "number_of_runs": 3,
                "precision": "fp8"
            }
        }
    }
}
